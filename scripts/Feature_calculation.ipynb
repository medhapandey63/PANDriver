{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7df1705f-cefe-4071-bab0-c37e423921b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mJupyter detected\u001b[0m\u001b[1;33m...\u001b[0m\n",
      "\u001b[1;32m2\u001b[0m\u001b[1;32m channel Terms of Service accepted\u001b[0m\n",
      "Retrieving notices: done\n",
      "Channels:\n",
      " - defaults\n",
      "Platform: osx-arm64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/medha/miniconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - keras\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    absl-py-2.3.1              |  py313hca03da5_0         433 KB\n",
      "    conda-26.1.0               |  py313hca03da5_0         1.2 MB\n",
      "    h5py-3.15.1                |  py313h2b875b3_1         1.1 MB\n",
      "    hdf5-1.14.5                |       hd77251f_2         5.6 MB\n",
      "    keras-3.13.2               |  py313h31cbfd0_0         3.7 MB\n",
      "    ml_dtypes-0.5.4            |  py313h3f644e9_0         226 KB\n",
      "    mpi-1.0                    |            mpich           5 KB\n",
      "    mpi4py-4.0.3               |  py313h63ebc28_1         708 KB\n",
      "    mpich-4.3.2                |       h3b86219_0         7.8 MB\n",
      "    namex-0.1.0                |  py313hca03da5_0          19 KB\n",
      "    optree-0.18.0              |  py313haeee614_0         380 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        21.2 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  absl-py            pkgs/main/osx-arm64::absl-py-2.3.1-py313hca03da5_0 \n",
      "  h5py               pkgs/main/osx-arm64::h5py-3.15.1-py313h2b875b3_1 \n",
      "  hdf5               pkgs/main/osx-arm64::hdf5-1.14.5-hd77251f_2 \n",
      "  keras              pkgs/main/osx-arm64::keras-3.13.2-py313h31cbfd0_0 \n",
      "  ml_dtypes          pkgs/main/osx-arm64::ml_dtypes-0.5.4-py313h3f644e9_0 \n",
      "  mpi                pkgs/main/osx-arm64::mpi-1.0-mpich \n",
      "  mpi4py             pkgs/main/osx-arm64::mpi4py-4.0.3-py313h63ebc28_1 \n",
      "  mpich              pkgs/main/osx-arm64::mpich-4.3.2-h3b86219_0 \n",
      "  namex              pkgs/main/osx-arm64::namex-0.1.0-py313hca03da5_0 \n",
      "  optree             pkgs/main/osx-arm64::optree-0.18.0-py313haeee614_0 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  conda              conda-forge::conda-25.11.1-py313h8f79~ --> pkgs/main::conda-26.1.0-py313hca03da5_0 \n",
      "\n",
      "\n",
      "Proceed ([y]/n)? ^C\n",
      "\n",
      "CondaSystemExit: \n",
      "Operation aborted.  Exiting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###### Calculate Structure based properties using AlphaFold Structures (requires PDB file)\n",
    "\n",
    "import csv\n",
    "from Bio.PDB import PDBParser, DSSP\n",
    "from Bio.PDB.Polypeptide import is_aa\n",
    "\n",
    "# load your structure\n",
    "p = PDBParser(QUIET=True)\n",
    "structure = p.get_structure(\"X\", \"your_structure.pdb\")\n",
    "\n",
    "model = structure[0]  # first model in PDB\n",
    "\n",
    "# run DSSP\n",
    "dssp = DSSP(model, \"../medha/AF-P04637-F1-model_v4.pdb\")\n",
    "\n",
    "# helper for polar/non-polar classification\n",
    "nonpolar = set([\"A\",\"V\",\"I\",\"L\",\"P\",\"F\",\"W\",\"M\"])\n",
    "polar    = set([\"G\",\"S\",\"T\",\"Y\",\"C\",\"N\",\"Q\",\"H\",\"K\",\"R\",\"D\",\"E\"])\n",
    "\n",
    "rows = []\n",
    "\n",
    "for key in dssp.keys():\n",
    "    res_idx = key[1][1]      # numeric position\n",
    "    aa      = dssp[key][1]   # one-letter residue name\n",
    "\n",
    "    if not is_aa(aa):\n",
    "        continue\n",
    "\n",
    "    asa         = dssp[key][3]\n",
    "    sec_str     = dssp[key][2]\n",
    "    phi         = dssp[key][4]\n",
    "    psi         = dssp[key][5]\n",
    "\n",
    "    # approximate ASA % \n",
    "    # (DSSP originally outputs relative ASA normalized by Gly-X-Gly max)\n",
    "    # Biopython stores this in dssp[key][3]\n",
    "    asa_per     = dssp[key][3] / dssp[key][2] if dssp[key][2] else 0\n",
    "\n",
    "    # hydrogen bonds\n",
    "    hb_donor     = len(dssp[key][7])\n",
    "    hb_acceptor  = len(dssp[key][8])\n",
    "\n",
    "    # side-chain vs main-chain ASA\n",
    "    sc_abs = dssp[key][3] - dssp[key][9]  # total ASA âˆ’ main chain ASA\n",
    "    mc_abs = dssp[key][9]\n",
    "    sc_real = sc_abs\n",
    "    mc_real = mc_abs\n",
    "\n",
    "    # polar vs nonpolar contributions (simple heuristic)\n",
    "    if aa in nonpolar:\n",
    "        nonpolar_abs  = asa\n",
    "        polar_abs     = 0\n",
    "    else:\n",
    "        polar_abs     = asa\n",
    "        nonpolar_abs  = 0\n",
    "\n",
    "    polar_real     = polar_abs\n",
    "    nonpolar_real  = nonpolar_abs\n",
    "\n",
    "    # for contact count (approx simple count of atoms within cutoff)\n",
    "    # if you want real contact count you can add a nearest neighbor search\n",
    "    contact_count  = 0\n",
    "\n",
    "    rows.append({\n",
    "        \"res\": aa,\n",
    "        \"pos\": res_idx,\n",
    "        \"ASA\": asa,\n",
    "        \"SEC_STR\": sec_str,\n",
    "        \"ASA_PER\": asa_per,\n",
    "        \"contact_count\": contact_count,\n",
    "        \"hb_donor\": hb_donor,\n",
    "        \"hb_acceptor\": hb_acceptor,\n",
    "        \"all_abs\": asa,\n",
    "        \"all_real\": asa,\n",
    "        \"sc_abs\": sc_abs,\n",
    "        \"sc_real\": sc_real,\n",
    "        \"mc_abs\": mc_abs,\n",
    "        \"mc_real\": mc_real,\n",
    "        \"Non_polar_abs\": nonpolar_abs,\n",
    "        \"Non_polar_real\": nonpolar_real,\n",
    "        \"polar_abs\": polar_abs,\n",
    "        \"polar_real\": polar_real,\n",
    "        \"ASA_PER_AVG\": asa_per\n",
    "    })\n",
    "\n",
    "# write as CSV\n",
    "with open(\"../tmp.csv\", \"w\", newline=\"\") as outf:\n",
    "    writer = csv.DictWriter(outf, fieldnames=list(rows[0].keys()))\n",
    "    writer.writeheader()\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(\"CSV written to dssp_output.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10c24aa3-33f8-4711-9f49-8411ab857f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/medha/miniconda3/lib/python3.13/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/var/folders/q3/d0_d_ddd4t1dznxqs6pvr8f40000gn/T/ipykernel_1720/399727967.py:273: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  all_prop.replace({'sec_strc':{'B':1, 'E':2, 'H':3, 'S':4, 'T':5, 'I':6, '-':0}}, inplace=True)\n",
      "/var/folders/q3/d0_d_ddd4t1dznxqs6pvr8f40000gn/T/ipykernel_1720/399727967.py:273: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  all_prop.replace({'sec_strc':{'B':1, 'E':2, 'H':3, 'S':4, 'T':5, 'I':6, '-':0}}, inplace=True)\n",
      "/var/folders/q3/d0_d_ddd4t1dznxqs6pvr8f40000gn/T/ipykernel_1720/399727967.py:273: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  all_prop.replace({'sec_strc':{'B':1, 'E':2, 'H':3, 'S':4, 'T':5, 'I':6, '-':0}}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "# from keras.models import load_model\n",
    "# from tensorflow.keras.layers import Dense\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, shutil, os, random\n",
    "import multiprocessing as mp\n",
    "# from Bio.PDB.ResidueDepth import ResidueDepth\n",
    "# from Bio.PDB import PDBList, PDBParser, NeighborSearch\n",
    "# from Bio.PDB.PDBParser import PDBParser\n",
    "import urllib\n",
    "# import networkx as nx\n",
    "# from tensorflow.keras.models import Sequential, model_from_json\n",
    "\n",
    "\n",
    "uniprot_seq = pd.read_excel(\"../medha/whole_proteome_uniprot_id.xlsx\",\n",
    "                            engine=\"openpyxl\")\n",
    "uniprot_seq.rename({\"From\":\"uniprot_ids\"}, axis=1, inplace =True)\n",
    "uniprot_seq['gene'] = uniprot_seq[\"Entry Name\"].apply(lambda x: x.split('_')[0])\n",
    "\n",
    "physicochem_properties_normalized = pd.read_csv('../medha/49_properties_normalizedValues.csv')\n",
    "physicochem_properties_actual = pd.read_csv('../medha/49_properties_numerical_Values.csv')\n",
    "new_463 = pd.read_csv('../medha/463_unique_numerical_properties.csv')\n",
    "\n",
    "mutation_matrices = pd.read_csv('../medha/aaindex_square_diagonal_properties.csv',\n",
    "                               keep_default_na=False)\n",
    "                               \n",
    "# overall_dataset = pd.read_csv('../medha/overall_dataset.csv')                      \n",
    "mutation_matrices.set_index('wild_mut', inplace=True)\n",
    "\n",
    "# list_proteins = [i.split('/')[-1].split('.')[0] for i in glob.glob('./data/structure-based-features/dssp/*')]\n",
    "input1 = ['P04637', 'R175D', 'P04637', 'R175S']\n",
    "# input1 = form.getfirst(\"input_seq\",\"0\").split()\n",
    "dataset = pd.DataFrame()\n",
    "for i in range(0, len(input1)-1,2):\n",
    "    uniprot_id = input1[i]\n",
    "    mutation = input1[i+1]\n",
    "    pos = int(mutation[1:-1])\n",
    "    sequence = next(iter(uniprot_seq.loc[uniprot_seq['uniprot_ids'] == uniprot_id, 'Sequence']))\n",
    "    gene = next(iter(uniprot_seq.loc[uniprot_seq['uniprot_ids'] == uniprot_id, 'gene']))\n",
    "    # if uniprot_id not in list_proteins:\n",
    "    #     print(\"The given protein and mutation does not belong to Cancer Gene Census!!\")\n",
    "    # Calculate sequence based features ###########\n",
    "    dict_to_store = {}\n",
    "    dict_to_store['UniProt ID'] = uniprot_id\n",
    "    dict_to_store['Mutation'] = mutation\n",
    "    #dataset = dataset.append(dict_to_store, ignore_index= True)\n",
    "    dataset = pd.concat([dataset, pd.DataFrame([dict_to_store])], ignore_index=True)\n",
    "     \n",
    "    # parser = PDBParser()\n",
    "    aa_dict = {\"ALA\": \"A\",\"ARG\": \"R\",\"ASN\": \"N\",\"ASP\": \"D\",\"CYS\": \"C\",\"GLN\": \"Q\",\"GLU\": \"E\",\"GLY\": \"G\",\"HIS\": \"H\",\"ILE\": \"I\",\n",
    "               \"LEU\": \"L\",\"LYS\": \"K\",\"MET\": \"M\",\"PHE\": \"F\",\"PRO\": \"P\",\"SER\": \"S\",\"THR\": \"T\",\"TRP\": \"W\",\"TYR\": \"Y\",\"VAL\": \"V\"}\n",
    "    motif_list = ['nM','Mc', 'n_M', 'M_c', 'n__M','M__c', 'tri']\n",
    "    # print(mutation_matrices.head())\n",
    "\n",
    "    physicochem_properties_actual1 = pd.concat([physicochem_properties_normalized, new_463[physicochem_properties_actual.columns]]).reset_index(drop =True)\n",
    "    aacon_header = ['mut_pos','KABAT', 'JORES', 'SCHNEIDER', 'SHENKIN', 'GERSTEIN',\n",
    "                    'TAYLOR_GAPS', 'TAYLOR_NO_GAPS', 'VELIBIL', 'KARLIN', 'ARMON',\n",
    "                    'THOMPSON', 'NOT_LANCET', 'MIRNY', 'WILLIAMSON', 'LANDGRAF',\n",
    "                    'SANDER', 'VALDAR', 'SMERFS']\n",
    "    list_prop = []\n",
    "    all_prop = pd.DataFrame()\n",
    "    for j in range(len(dataset)):\n",
    "    # def calls(i, all_prop = all_prop):\n",
    "        uniprot_id = dataset['UniProt ID'][j]\n",
    "        mutation = dataset['Mutation'][j]\n",
    "        wild = mutation[0]\n",
    "        mut = mutation[-1]\n",
    "        wild_mut = wild+mut\n",
    "        pos = int(mutation[1:-1])\n",
    "        sequence = next(iter(uniprot_seq.loc[uniprot_seq['uniprot_ids'] == uniprot_id, 'Sequence']))\n",
    "        if pos-7 < 0:\n",
    "            window_13 = sequence[0:pos+6]\n",
    "        elif pos+6>len(sequence):\n",
    "            window_13 = sequence[pos-7:]\n",
    "        else:\n",
    "            window_13 = sequence[pos-7:pos+6]\\\n",
    "\n",
    "        gene = next(iter(uniprot_seq.loc[uniprot_seq['uniprot_ids'] == uniprot_id, 'gene']))\n",
    "        if len(sequence) >= pos and wild == sequence[pos-1]:\n",
    "            f4 = open(f\"../medha/{uniprot_id}.pssm\", \"r\").readlines()[2:]\n",
    "            f_aacon = pd.read_csv(f\"../medha/{uniprot_id}.csv\", skiprows=1, names = aacon_header)\n",
    "            f_disorder = pd.read_csv(f\"../medha/{uniprot_id}_IUPred.csv\")\n",
    "            f_residue_depth = pd.read_csv(f\"../medha/{uniprot_id}_residue_depth.csv\")\n",
    "            f_plDDT = pd.read_csv(f\"../medha/{uniprot_id}_plDDT.out\")\n",
    "            f_dssp = pd.read_csv(f\"../medha/{uniprot_id}.out\")\n",
    "            df_network1 = pd.read_csv(f\"../medha/{uniprot_id}_network.csv\")\n",
    "            contact_type = [uniprot_id+'_aroaro.csv', uniprot_id+'_arosul.csv', uniprot_id+'_cationpi.csv',\n",
    "                    uniprot_id+'_disulphide.csv', uniprot_id+'_hbond_main_main.csv', uniprot_id+'_hbond_main_side.csv',\n",
    "                    uniprot_id+'_hbond_side_side.csv', uniprot_id+'_hydrophobic.csv', uniprot_id+'_ionic.csv']\n",
    "\n",
    "            dict_prop = dict()\n",
    "            dict_prop['Wild'] = wild\n",
    "            dict_prop['Mut'] = mutation[-1]\n",
    "            dict_prop['Pos'] = pos\n",
    "            # dict_prop['Class'] = dataset['Class'][i]\n",
    "            dict_prop['UniProt ID'] = uniprot_id\n",
    "            dict_prop['Gene Name'] = gene\n",
    "            dict_prop['Mutation'] = mutation\n",
    "\n",
    "            a = sum(physicochem_properties_normalized[window_13[k]] for k in range(len(window_13)))/sum(c.isalpha() for c in window_13)\n",
    "            b = sum(physicochem_properties_actual1[window_13[k]] for k in range(len(window_13)))/sum(c.isalpha() for c in window_13)\n",
    "            j = 0\n",
    "            for property1 in physicochem_properties_normalized['index']:\n",
    "                dict_prop[property1+'_normalize_site_value'] = physicochem_properties_normalized.loc[physicochem_properties_normalized['index'] == property1][wild].tolist()[0]\n",
    "                dict_prop[property1+'_normalize'] = a[j]\n",
    "                dict_prop[property1+'_normalize_diff'] = a[j]- physicochem_properties_normalized.loc[physicochem_properties_normalized['index'] == property1][mut].tolist()[0] + physicochem_properties_normalized.loc[physicochem_properties_normalized['index'] == property1][wild].tolist()[0]\n",
    "\n",
    "                if property1 == \"pK'\":\n",
    "                    dict_prop[property1+'_numeric_site_value'] = physicochem_properties_actual1.loc[physicochem_properties_actual1['index'] == \"pK'\"][wild].tolist()[0]\n",
    "                    dict_prop[property1+'_numeric_values'] =  b[j]\n",
    "                    dict_prop[property1+'_numeric_diff'] = b[j]-physicochem_properties_actual1.loc[physicochem_properties_actual1['index'] == \"pK'\"][mut].tolist()[0]-physicochem_properties_actual1.loc[physicochem_properties_actual1['index'] == \"pK'\"][wild].tolist()[0]\n",
    "                else:\n",
    "                    dict_prop[property1+'_numeric_site_value'] = physicochem_properties_actual1.loc[physicochem_properties_actual1['index'] == \"pK'\"][wild].tolist()[0]\n",
    "                    dict_prop[property1+'_numeric_values'] =  b[j]\n",
    "                    dict_prop[property1+'_numeric_diff'] = b[j]-physicochem_properties_actual1.loc[physicochem_properties_actual1['index'] == \"pK'\"][mut].tolist()[0]-physicochem_properties_actual1.loc[physicochem_properties_actual1['index'] == \"pK'\"][wild].tolist()[0]\n",
    "        #         dict_prop[property1+'_diff'] = physicochem_properties.loc[physicochem_properties['index'] == property1][wild_mut[-1]].tolist()[0] - physicochem_properties.loc[physicochem_properties['index'] == property1][wild_mut[0]].tolist()[0]\n",
    "                j += 1\n",
    "            sul_c = len(re.findall('[CM]', window_13))\n",
    "            pos_c = len(re.findall('[KRH]', window_13))\n",
    "            aliphatic = len(re.findall('[GALIV]', window_13))\n",
    "            arom = len(re.findall('[YFW]', window_13))\n",
    "            neg_c = len(re.findall('[DE]', window_13))\n",
    "            polar = len(re.findall('[NQSTP]', window_13))\n",
    "            dict_prop['neg_charge'] = neg_c\n",
    "            dict_prop['polar'] = polar\n",
    "            dict_prop['aromatic'] = arom\n",
    "            dict_prop['S_containing'] = sul_c\n",
    "            dict_prop['aliphatic'] = aliphatic\n",
    "\n",
    "            n_ter_wild = wild+sequence[pos-2]\n",
    "            n_ter_mut = mut+sequence[pos-2]\n",
    "            if pos >= len(sequence):\n",
    "                c_ter_wild = wild + '-'\n",
    "                c_ter_mut = mut + '-'\n",
    "            else:\n",
    "                c_ter_wild = wild + sequence[pos]\n",
    "                c_ter_mut = mut+sequence[pos]\n",
    "            property_n = mutation_matrices.loc[n_ter_mut]- mutation_matrices.loc[n_ter_wild]\n",
    "            try:\n",
    "                property_c = mutation_matrices.loc[c_ter_mut]- mutation_matrices.loc[c_ter_wild]\n",
    "            except KeyError:\n",
    "                property_c = mutation_matrices.loc['AG'] - mutation_matrices.loc['AG']\n",
    "            #print(property_n, property_c, i)\n",
    "            for mut_prop in property_n.index:\n",
    "                dict_prop[mut_prop] = property_n[mut_prop]\n",
    "                dict_prop[mut_prop.lower()] = property_c[mut_prop]\n",
    "    #         data_with_seq1 = pd.concat([data_with_seq,df_mutation_matrices_c,df_mutation_matrices_n], axis=1)\n",
    "    ########    Odds ratio based features  #######################################\n",
    "            if pos>=len(sequence):\n",
    "                n_ter = '-'\n",
    "                dipep_n = n_ter+wild\n",
    "                gap2_n = n_ter+wild\n",
    "            else:\n",
    "                n_ter = sequence[pos-2]\n",
    "                dipep_n = n_ter+wild\n",
    "                gap2_n = sequence[pos-4]+\"**\"+wild\n",
    "\n",
    "            if pos>=len(sequence):\n",
    "                n_ter_gap = '-'\n",
    "                dipep_gap_n = n_ter_gap+\"*\"+wild\n",
    "            else:\n",
    "                n_ter_gap = sequence[pos-3]\n",
    "                dipep_gap_n = n_ter_gap+\"*\"+wild\n",
    "\n",
    "            if pos+1 >= len(sequence):\n",
    "                    c_ter_gap = '-'\n",
    "                    dipep_gap_c = wild + c_ter_gap\n",
    "                    gap2_c = wild + c_ter_gap\n",
    "            else:\n",
    "                c_ter_gap = sequence[pos+1]\n",
    "                dipep_gap_c = wild +\"*\"+ c_ter_gap\n",
    "        #        print(uni_id,gap2_c)\n",
    "                try:\n",
    "                    gap2_c = wild +\"**\"+ sequence[pos+2]\n",
    "                except IndexError:\n",
    "                    gap2_c = wild +\"**\"+c_ter_gap\n",
    "            if pos >= len(sequence):\n",
    "                c_ter = '-'\n",
    "                dipep_c = wild+c_ter\n",
    "            else:\n",
    "                c_ter = sequence[pos]\n",
    "                dipep_c = wild+c_ter\n",
    "            tripep = n_ter+ wild+c_ter\n",
    "            dict_prop['nM'] = dipep_n\n",
    "            dict_prop['Mc']= dipep_c\n",
    "            dict_prop['tri'] = tripep\n",
    "            dict_prop['n_M']=dipep_gap_n\n",
    "            dict_prop['M_c'] = dipep_gap_c\n",
    "            dict_prop['n__M'] = gap2_n\n",
    "            dict_prop['M__c'] = gap2_c\n",
    "    #        print(df_out['nM'],df_out['Mc'],df_out['tri'],df_out['n_M'],df_out['M_c'],df_out['n__M'],df_out['M__c'])\n",
    "        # =============================================================================\n",
    "        # odds ratio\n",
    "            motif_list = ['nM','Mc', 'n_M', 'M_c', 'n__M','M__c', 'tri']\n",
    "            for motif in motif_list:\n",
    "                # print(motif)\n",
    "                x =  pd.read_excel('../medha/BRCA_odds_ratio.xlsx',sheet_name= motif)\n",
    "                # print(motif, x.head())\n",
    "                entry = dict_prop[motif]\n",
    "                required_odd_ratio = x[x[motif] == entry]\n",
    "                conditions = [(required_odd_ratio['odd_ratio'] >= 1.2) | (required_odd_ratio['odd_ratio'] == 'inf'),\n",
    "                (required_odd_ratio['odd_ratio'] < 1.2) & (required_odd_ratio['odd_ratio'] >= 0.9),\n",
    "                (required_odd_ratio['odd_ratio'] < 0.9)]\n",
    "                condition_values = [1,3,2]\n",
    "                dict_prop[motif+'_coded_odds'] = next(iter(np.select(conditions, condition_values)))\n",
    "                dict_prop[motif+'_odds_ratio'] = next(iter(required_odd_ratio['odd_ratio']))\n",
    "            # try\n",
    "            xx_network = df_network1[(df_network1['Wild'] == wild) & (df_network1['pos'] == pos)]\n",
    "            # print(xx_network)\n",
    "            if len(xx_network)> 0:\n",
    "                dict_prop['Degree_centrality'] = next(iter(xx_network['Degree centrality']))\n",
    "                dict_prop['Closeness_centrality'] = next(iter(xx_network['Closeness centrality']))\n",
    "                dict_prop['betweenness_centrality'] = next(iter(xx_network['Betweenness centrality']))\n",
    "                dict_prop['eigenvector_centrality'] = next(iter(xx_network['Eigenvector centrality']))\n",
    "            else:\n",
    "                dict_prop['Degree_centrality'] = 0\n",
    "                dict_prop['Closeness_centrality'] = 0\n",
    "                dict_prop['betweenness_centrality'] = 0\n",
    "                dict_prop['eigenvector_centrality'] = 0\n",
    "            # except\n",
    "            dict1 = {'A':f4[pos].strip().split()[2:][0], 'R':f4[pos].strip().split()[2:][1],\n",
    "                     'N':f4[pos].strip().split()[2:][2], 'D':f4[pos].strip().split()[2:][3],\n",
    "                     'C':f4[pos].strip().split()[2:][4], 'Q':f4[pos].strip().split()[2:][5],\n",
    "                     'E':f4[pos].strip().split()[2:][6], 'G':f4[pos].strip().split()[2:][7],\n",
    "                     'H':f4[pos].strip().split()[2:][8], 'I':f4[pos].strip().split()[2:][9],\n",
    "                     'L':f4[pos].strip().split()[2:][10], 'K':f4[pos].strip().split()[2:][11],\n",
    "                     'M':f4[pos].strip().split()[2:][12], 'F':f4[pos].strip().split()[2:][13],\n",
    "                     'P':f4[pos].strip().split()[2:][14], 'S':f4[pos].strip().split()[2:][15],\n",
    "                     'T':f4[pos].strip().split()[2:][16], 'W':f4[pos].strip().split()[2:][17],\n",
    "                     'Y':f4[pos].strip().split()[2:][18], 'V':f4[pos].strip().split()[2:][19]}\n",
    "            dict_prop['pssm_score1'] =  int(dict1[wild])\n",
    "            #             dict_prop['pssm_score1'] =  dict1[site[0]]\n",
    "            dict_prop['pssm_score2'] = sum([int(i) for i in dict1.values()])/20\n",
    "            dict_prop['pssm_score3'] = int(dict1[mutation[-1]])-int(dict1[wild])\n",
    "            cons= f4[pos].strip('\\n')[90:].split()[21:22]\n",
    "            if len(cons) ==0:\n",
    "                dict_prop['conservation']= 0\n",
    "            else:\n",
    "                for element in cons:\n",
    "                    dict_prop['conservation']= float(element)\n",
    "            mm = f_aacon.iloc[pos-1]\n",
    "            for item in aacon_header:\n",
    "                dict_prop[item] = mm[item]\n",
    "            dict_prop['disorder'] = next(iter(f_disorder[f_disorder['Pos'] == pos]['IUPRED SCORE']))\n",
    "            if pos > len(f_dssp):\n",
    "                dict_prop['sec_strc'] = random.choice('BEGHIST')\n",
    "                dict_prop['ASA'] = np.average(f_dssp['ASA'])\n",
    "                dict_prop['plDDT'] = np.average(f_plDDT['Avg. B-factor'])\n",
    "                dict_prop['f_residue_depth'] = np.average(f_residue_depth['depth'])\n",
    "            else:\n",
    "                dict_prop['sec_strc'] = f_dssp.iloc[pos-1]['SS']\n",
    "                dict_prop['ASA'] = f_dssp.iloc[pos-1]['ASA']\n",
    "                dict_prop['plDDT'] = next(iter(f_plDDT[f_plDDT['Residue'] == pos]['Avg. B-factor']))\n",
    "                dict_prop['f_residue_depth'] = next(iter(f_residue_depth[f_residue_depth['pos'] == pos]['depth']))\n",
    "            for f_type in contact_type:\n",
    "                df_bonds = pd.read_csv('../medha/structure_specific_interactions/'+f_type)\n",
    "                df_bonds['Res1'] = df_bonds['RES1 '].apply(lambda x: aa_dict[x.strip()])\n",
    "                df_bonds['Res2'] = df_bonds[' RES2 '].apply(lambda x: aa_dict[x.strip()])\n",
    "                df_bonds.rename({' idRES1 ':'pos1', ' idRES2 ':'pos2'}, axis =1, inplace =True)\n",
    "                df_bonds['mut_pos'] = df_bonds['Res1']+df_bonds['pos1'].astype(str)\n",
    "                dict_prop[f_type.split('_')[-1].split('.')[0]] = len(df_bonds[df_bonds['pos1']== pos])\n",
    "            \n",
    "            #all_prop = all_prop.append(dict_prop, ignore_index =True)\n",
    "            all_prop = pd.concat(\n",
    "            [all_prop, pd.DataFrame([dict_prop])],\n",
    "            ignore_index=True\n",
    "            )\n",
    "            all_prop.replace({'sec_strc':{'B':1, 'E':2, 'H':3, 'S':4, 'T':5, 'I':6, '-':0}}, inplace=True)\n",
    "\n",
    "all_prop.to_csv('../complete_dataset_with_features.csv', index = False)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c09c34e-3c43-44d5-a54a-16bebc0f2762",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/medha/miniconda3/lib/python3.13/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: ../complete_dataset_with_features.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Feature generation script (cleaned + labeled)\n",
    "\n",
    "Inputs expected (per UniProt ID):\n",
    "- ../medha/whole_proteome_uniprot_id.xlsx                (Sequence, Entry Name, From->uniprot_ids)\n",
    "- ../medha/49_properties_normalizedValues.csv            (physicochemical properties; normalized)\n",
    "- ../medha/49_properties_numerical_Values.csv            (physicochemical properties; numeric)\n",
    "- ../medha/463_unique_numerical_properties.csv           (additional numeric properties)\n",
    "- ../medha/aaindex_square_diagonal_properties.csv        (AAindex mutation matrices; wild_mut index)\n",
    "- ../medha/{uniprot_id}.pssm                             (PSSM file)\n",
    "- ../medha/{uniprot_id}.csv                              (AACon conservation features)\n",
    "- ../medha/{uniprot_id}_IUPred.csv                        (disorder)\n",
    "- ../medha/{uniprot_id}_residue_depth.csv                 (residue depth)\n",
    "- ../medha/{uniprot_id}_plDDT.out                         (plDDT / B-factor per residue)\n",
    "- ../medha/{uniprot_id}.out                               (DSSP-like output with SS, ASA columns)\n",
    "- ../medha/{uniprot_id}_network.csv                       (network centrality features)\n",
    "- ../medha/structure_specific_interactions/{uniprot_id}_*.csv (interaction/contact files)\n",
    "\n",
    "Output:\n",
    "- ../complete_dataset_with_features.csv\n",
    "\"\"\"\n",
    "\n",
    "import random\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# CONFIG / INPUTS\n",
    "# -----------------------------\n",
    "INPUT_MUTATIONS = ['P04637', 'R175D', 'P04637', 'R175S']  # [uniprot, mut, uniprot, mut, ...]\n",
    "BASE_DIR = \"../medha\"\n",
    "OUT_CSV = \"../complete_dataset_with_features.csv\"\n",
    "\n",
    "AA3_TO_AA1 = {\n",
    "    \"ALA\": \"A\", \"ARG\": \"R\", \"ASN\": \"N\", \"ASP\": \"D\", \"CYS\": \"C\",\n",
    "    \"GLN\": \"Q\", \"GLU\": \"E\", \"GLY\": \"G\", \"HIS\": \"H\", \"ILE\": \"I\",\n",
    "    \"LEU\": \"L\", \"LYS\": \"K\", \"MET\": \"M\", \"PHE\": \"F\", \"PRO\": \"P\",\n",
    "    \"SER\": \"S\", \"THR\": \"T\", \"TRP\": \"W\", \"TYR\": \"Y\", \"VAL\": \"V\"\n",
    "}\n",
    "\n",
    "MOTIFS = ['nM', 'Mc', 'n_M', 'M_c', 'n__M', 'M__c', 'tri']\n",
    "\n",
    "AACON_HEADER = [\n",
    "    'mut_pos', 'KABAT', 'JORES', 'SCHNEIDER', 'SHENKIN', 'GERSTEIN',\n",
    "    'TAYLOR_GAPS', 'TAYLOR_NO_GAPS', 'VELIBIL', 'KARLIN', 'ARMON',\n",
    "    'THOMPSON', 'NOT_LANCET', 'MIRNY', 'WILLIAMSON', 'LANDGRAF',\n",
    "    'SANDER', 'VALDAR', 'SMERFS'\n",
    "]\n",
    "\n",
    "CONTACT_FILES = [\n",
    "    \"_aroaro.csv\", \"_arosul.csv\", \"_cationpi.csv\", \"_disulphide.csv\",\n",
    "    \"_hbond_main_main.csv\", \"_hbond_main_side.csv\", \"_hbond_side_side.csv\",\n",
    "    \"_hydrophobic.csv\", \"_ionic.csv\"\n",
    "]\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# LOAD REFERENCE TABLES\n",
    "# -----------------------------\n",
    "uniprot_seq = pd.read_excel(f\"{BASE_DIR}/whole_proteome_uniprot_id.xlsx\", engine=\"openpyxl\")\n",
    "uniprot_seq.rename({\"From\": \"uniprot_ids\"}, axis=1, inplace=True)\n",
    "uniprot_seq[\"gene\"] = uniprot_seq[\"Entry Name\"].apply(lambda x: x.split(\"_\")[0])\n",
    "\n",
    "physchem_norm = pd.read_csv(f\"{BASE_DIR}/49_properties_normalizedValues.csv\")\n",
    "physchem_num = pd.read_csv(f\"{BASE_DIR}/49_properties_numerical_Values.csv\")\n",
    "extra_463 = pd.read_csv(f\"{BASE_DIR}/463_unique_numerical_properties.csv\")\n",
    "\n",
    "# NOTE: This creates a numeric-property table with the same columns as physchem_num\n",
    "physchem_num_all = pd.concat([physchem_norm, extra_463[physchem_num.columns]], ignore_index=True)\n",
    "\n",
    "mutation_matrices = pd.read_csv(\n",
    "    f\"{BASE_DIR}/aaindex_square_diagonal_properties.csv\",\n",
    "    keep_default_na=False\n",
    ")\n",
    "mutation_matrices.set_index(\"wild_mut\", inplace=True)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# HELPER FUNCTIONS\n",
    "# -----------------------------\n",
    "def get_sequence_and_gene(uniprot_id: str):\n",
    "    seq = next(iter(uniprot_seq.loc[uniprot_seq[\"uniprot_ids\"] == uniprot_id, \"Sequence\"]))\n",
    "    gene = next(iter(uniprot_seq.loc[uniprot_seq[\"uniprot_ids\"] == uniprot_id, \"gene\"]))\n",
    "    return seq, gene\n",
    "\n",
    "\n",
    "def window_13mer(sequence: str, pos_1based: int) -> str:\n",
    "    \"\"\"13-aa window centered on position; handles ends.\"\"\"\n",
    "    pos0 = pos_1based - 1\n",
    "    left = max(0, pos0 - 6)\n",
    "    right = min(len(sequence), pos0 + 7)\n",
    "    return sequence[left:right]\n",
    "\n",
    "\n",
    "def safe_get(series, default=0):\n",
    "    try:\n",
    "        return next(iter(series))\n",
    "    except StopIteration:\n",
    "        return default\n",
    "\n",
    "\n",
    "def compute_dipeptide_motifs(sequence: str, pos_1based: int, wild: str):\n",
    "    \"\"\"Motifs used for odds-ratio lookup.\"\"\"\n",
    "    pos0 = pos_1based - 1\n",
    "\n",
    "    # N-terminal neighbors\n",
    "    n1 = sequence[pos0 - 1] if pos0 - 1 >= 0 else '-'\n",
    "    n2 = sequence[pos0 - 2] if pos0 - 2 >= 0 else '-'\n",
    "    n4 = sequence[pos0 - 4] if pos0 - 4 >= 0 else '-'\n",
    "\n",
    "    # C-terminal neighbors\n",
    "    c1 = sequence[pos0 + 1] if pos0 + 1 < len(sequence) else '-'\n",
    "    c2 = sequence[pos0 + 2] if pos0 + 2 < len(sequence) else '-'\n",
    "    c0 = sequence[pos0 + 0] if pos0 < len(sequence) else '-'\n",
    "\n",
    "    motifs = {}\n",
    "    motifs[\"nM\"] = n1 + wild\n",
    "    motifs[\"Mc\"] = wild + c0\n",
    "    motifs[\"tri\"] = n1 + wild + c0\n",
    "    motifs[\"n_M\"] = n2 + \"*\" + wild\n",
    "    motifs[\"M_c\"] = wild + \"*\" + c1\n",
    "    motifs[\"n__M\"] = (n4 + \"**\" + wild) if n4 != '-' else ('-' + wild)\n",
    "    motifs[\"M__c\"] = wild + \"**\" + (c2 if c2 != '-' else c1)\n",
    "\n",
    "    return motifs\n",
    "\n",
    "\n",
    "def add_physchem_features(dict_prop, wild, mut, win13):\n",
    "    \"\"\"\n",
    "    Feature group: Physicochemical properties\n",
    "    - site values (wild)\n",
    "    - window mean (13-mer)\n",
    "    - diff-like features\n",
    "    \"\"\"\n",
    "    # window means across residues (ignoring non-letters)\n",
    "    denom = sum(c.isalpha() for c in win13)\n",
    "    a = sum(physchem_norm[win13[k]] for k in range(len(win13))) / denom\n",
    "    b = sum(physchem_num_all[win13[k]] for k in range(len(win13))) / denom\n",
    "\n",
    "    j = 0\n",
    "    for prop_name in physchem_norm[\"index\"]:\n",
    "        # normalized\n",
    "        wild_norm = physchem_norm.loc[physchem_norm[\"index\"] == prop_name, wild].tolist()[0]\n",
    "        mut_norm = physchem_norm.loc[physchem_norm[\"index\"] == prop_name, mut].tolist()[0]\n",
    "        dict_prop[f\"{prop_name}_normalize_site_value\"] = wild_norm\n",
    "        dict_prop[f\"{prop_name}_normalize\"] = a[j]\n",
    "        dict_prop[f\"{prop_name}_normalize_diff\"] = a[j] - mut_norm + wild_norm\n",
    "\n",
    "        # numeric (FIX: original code accidentally used \"pK'\" row for everything)\n",
    "        wild_num = physchem_num_all.loc[physchem_num_all[\"index\"] == prop_name, wild].tolist()[0]\n",
    "        mut_num = physchem_num_all.loc[physchem_num_all[\"index\"] == prop_name, mut].tolist()[0]\n",
    "        dict_prop[f\"{prop_name}_numeric_site_value\"] = wild_num\n",
    "        dict_prop[f\"{prop_name}_numeric_values\"] = b[j]\n",
    "        dict_prop[f\"{prop_name}_numeric_diff\"] = b[j] - mut_num + wild_num\n",
    "\n",
    "        j += 1\n",
    "\n",
    "    # Feature group: amino-acid class composition in 13-mer window\n",
    "    dict_prop[\"neg_charge\"] = len(re.findall(\"[DE]\", win13))\n",
    "    dict_prop[\"polar\"] = len(re.findall(\"[NQSTP]\", win13))\n",
    "    dict_prop[\"aromatic\"] = len(re.findall(\"[YFW]\", win13))\n",
    "    dict_prop[\"S_containing\"] = len(re.findall(\"[CM]\", win13))\n",
    "    dict_prop[\"aliphatic\"] = len(re.findall(\"[GALIV]\", win13))\n",
    "\n",
    "\n",
    "def add_mutation_matrix_features(dict_prop, sequence, pos, wild, mut):\n",
    "    \"\"\"\n",
    "    Feature group: AAIndex mutation matrices\n",
    "    - N-terminal context (mut_prop)\n",
    "    - C-terminal context (lowercase mut_prop)\n",
    "    \"\"\"\n",
    "    pos0 = pos - 1\n",
    "\n",
    "    # N-terminal dipeptide: (wild + previous residue)\n",
    "    prev_res = sequence[pos0 - 1] if pos0 - 1 >= 0 else \"-\"\n",
    "    n_wild = wild + prev_res\n",
    "    n_mut = mut + prev_res\n",
    "\n",
    "    # C-terminal dipeptide: (wild + next residue)\n",
    "    next_res = sequence[pos0 + 1] if pos0 + 1 < len(sequence) else \"-\"\n",
    "    c_wild = wild + next_res\n",
    "    c_mut = mut + next_res\n",
    "\n",
    "    property_n = mutation_matrices.loc[n_mut] - mutation_matrices.loc[n_wild]\n",
    "    try:\n",
    "        property_c = mutation_matrices.loc[c_mut] - mutation_matrices.loc[c_wild]\n",
    "    except KeyError:\n",
    "        property_c = mutation_matrices.loc[\"AG\"] - mutation_matrices.loc[\"AG\"]\n",
    "\n",
    "    for mut_prop in property_n.index:\n",
    "        dict_prop[mut_prop] = property_n[mut_prop]\n",
    "        dict_prop[mut_prop.lower()] = property_c[mut_prop]\n",
    "\n",
    "\n",
    "def add_odds_ratio_features(dict_prop, motifs):\n",
    "    \"\"\"\n",
    "    Feature group: Motif odds-ratio (from Excel sheets per motif)\n",
    "    Creates:\n",
    "    - {motif}_coded_odds\n",
    "    - {motif}_odds_ratio\n",
    "    \"\"\"\n",
    "    for motif in MOTIFS:\n",
    "        x = pd.read_excel(f\"{BASE_DIR}/BRCA_odds_ratio.xlsx\", sheet_name=motif)\n",
    "        entry = motifs[motif]\n",
    "        row = x[x[motif] == entry]\n",
    "\n",
    "        odd = safe_get(row[\"odd_ratio\"], default=0)\n",
    "\n",
    "        # Coded odds bins\n",
    "        conditions = [\n",
    "            (row[\"odd_ratio\"] >= 1.2) | (row[\"odd_ratio\"] == \"inf\"),\n",
    "            (row[\"odd_ratio\"] < 1.2) & (row[\"odd_ratio\"] >= 0.9),\n",
    "            (row[\"odd_ratio\"] < 0.9),\n",
    "        ]\n",
    "        code_vals = [1, 3, 2]\n",
    "        dict_prop[f\"{motif}_coded_odds\"] = safe_get(np.select(conditions, code_vals), default=0)\n",
    "        dict_prop[f\"{motif}_odds_ratio\"] = odd\n",
    "\n",
    "\n",
    "def add_network_features(dict_prop, df_network, wild, pos):\n",
    "    \"\"\"\n",
    "    Feature group: Structural network centrality\n",
    "    \"\"\"\n",
    "    xx = df_network[(df_network[\"Wild\"] == wild) & (df_network[\"pos\"] == pos)]\n",
    "    if len(xx) > 0:\n",
    "        dict_prop[\"Degree_centrality\"] = safe_get(xx[\"Degree centrality\"], 0)\n",
    "        dict_prop[\"Closeness_centrality\"] = safe_get(xx[\"Closeness centrality\"], 0)\n",
    "        dict_prop[\"betweenness_centrality\"] = safe_get(xx[\"Betweenness centrality\"], 0)\n",
    "        dict_prop[\"eigenvector_centrality\"] = safe_get(xx[\"Eigenvector centrality\"], 0)\n",
    "    else:\n",
    "        dict_prop[\"Degree_centrality\"] = 0\n",
    "        dict_prop[\"Closeness_centrality\"] = 0\n",
    "        dict_prop[\"betweenness_centrality\"] = 0\n",
    "        dict_prop[\"eigenvector_centrality\"] = 0\n",
    "\n",
    "\n",
    "def add_pssm_features(dict_prop, f4_lines, pos, wild, mut):\n",
    "    \"\"\"\n",
    "    Feature group: PSSM / conservation\n",
    "    \"\"\"\n",
    "    # PSSM line indexing: original code uses f4[pos] (1-basedish). Keep as-is to match their files.\n",
    "    cols = f4_lines[pos].strip().split()\n",
    "\n",
    "    aa_scores = cols[2:22]  # 20 AAs\n",
    "    aa_order = list(\"ARNDCQEGHILKMFPSTWYV\")\n",
    "\n",
    "    score_map = dict(zip(aa_order, aa_scores))\n",
    "    score_map = {k: int(v) for k, v in score_map.items()}\n",
    "\n",
    "    dict_prop[\"pssm_score1\"] = score_map.get(wild, 0)\n",
    "    dict_prop[\"pssm_score2\"] = sum(score_map.values()) / 20.0\n",
    "    dict_prop[\"pssm_score3\"] = score_map.get(mut, 0) - score_map.get(wild, 0)\n",
    "\n",
    "    # Conservation: original code slices at char 90; keep behavior\n",
    "    cons = f4_lines[pos].strip(\"\\n\")[90:].split()[21:22]\n",
    "    dict_prop[\"conservation\"] = float(cons[0]) if len(cons) else 0.0\n",
    "\n",
    "\n",
    "def add_aacon_features(dict_prop, f_aacon, pos):\n",
    "    \"\"\"\n",
    "    Feature group: AACon conservation features (per residue)\n",
    "    \"\"\"\n",
    "    mm = f_aacon.iloc[pos - 1]\n",
    "    for item in AACON_HEADER:\n",
    "        dict_prop[item] = mm[item]\n",
    "\n",
    "\n",
    "def add_disorder_depth_plddt_dssp(dict_prop, f_disorder, f_depth, f_plddt, f_dssp, pos):\n",
    "    \"\"\"\n",
    "    Feature group: Disorder + structure features\n",
    "    - disorder (IUPred)\n",
    "    - DSSP secondary structure + ASA\n",
    "    - plDDT\n",
    "    - residue depth\n",
    "    \"\"\"\n",
    "    dict_prop[\"disorder\"] = safe_get(\n",
    "        f_disorder.loc[f_disorder[\"Pos\"] == pos, \"IUPRED SCORE\"],\n",
    "        default=0\n",
    "    )\n",
    "\n",
    "    # DSSP and other structure files: if residue missing, use averages/random SS\n",
    "    if pos > len(f_dssp):\n",
    "        dict_prop[\"sec_strc\"] = random.choice(list(\"BEGHIST-\"))\n",
    "        dict_prop[\"ASA\"] = float(np.average(f_dssp[\"ASA\"])) if len(f_dssp) else 0\n",
    "        dict_prop[\"plDDT\"] = float(np.average(f_plddt[\"Avg. B-factor\"])) if len(f_plddt) else 0\n",
    "        dict_prop[\"f_residue_depth\"] = float(np.average(f_depth[\"depth\"])) if len(f_depth) else 0\n",
    "    else:\n",
    "        dict_prop[\"sec_strc\"] = f_dssp.iloc[pos - 1][\"SS\"]\n",
    "        dict_prop[\"ASA\"] = f_dssp.iloc[pos - 1][\"ASA\"]\n",
    "        dict_prop[\"plDDT\"] = safe_get(\n",
    "            f_plddt.loc[f_plddt[\"Residue\"] == pos, \"Avg. B-factor\"],\n",
    "            default=0\n",
    "        )\n",
    "        dict_prop[\"f_residue_depth\"] = safe_get(\n",
    "            f_depth.loc[f_depth[\"pos\"] == pos, \"depth\"],\n",
    "            default=0\n",
    "        )\n",
    "\n",
    "\n",
    "def add_structure_interaction_counts(dict_prop, uniprot_id, pos):\n",
    "    \"\"\"\n",
    "    Feature group: Structure-specific interaction/contact counts\n",
    "    Each file contributes one count feature keyed by interaction type.\n",
    "    \"\"\"\n",
    "    for suffix in CONTACT_FILES:\n",
    "        f_type = f\"{uniprot_id}{suffix}\"\n",
    "        df_bonds = pd.read_csv(f\"{BASE_DIR}/structure_specific_interactions/{f_type}\")\n",
    "\n",
    "        # Normalize residue labels and positions\n",
    "        df_bonds[\"Res1\"] = df_bonds[\"RES1 \"].apply(lambda x: AA3_TO_AA1[x.strip()])\n",
    "        df_bonds[\"Res2\"] = df_bonds[\" RES2 \"].apply(lambda x: AA3_TO_AA1[x.strip()])\n",
    "        df_bonds.rename({\" idRES1 \": \"pos1\", \" idRES2 \": \"pos2\"}, axis=1, inplace=True)\n",
    "\n",
    "        interaction_name = f_type.split(\"_\")[-1].split(\".\")[0]\n",
    "        dict_prop[interaction_name] = int((df_bonds[\"pos1\"] == pos).sum())\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# MAIN: BUILD FEATURE TABLE\n",
    "# -----------------------------\n",
    "all_rows = []\n",
    "\n",
    "for i in range(0, len(INPUT_MUTATIONS) - 1, 2):\n",
    "    uniprot_id = INPUT_MUTATIONS[i]\n",
    "    mutation = INPUT_MUTATIONS[i + 1]\n",
    "\n",
    "    wild = mutation[0]\n",
    "    mut = mutation[-1]\n",
    "    pos = int(mutation[1:-1])  # 1-based residue index\n",
    "\n",
    "    sequence, gene = get_sequence_and_gene(uniprot_id)\n",
    "\n",
    "    # Basic validation: position exists and wild matches sequence at that position\n",
    "    if not (1 <= pos <= len(sequence)) or sequence[pos - 1] != wild:\n",
    "        # Skip invalid entries (instead of silently doing nothing)\n",
    "        continue\n",
    "\n",
    "    win13 = window_13mer(sequence, pos)\n",
    "    motifs = compute_dipeptide_motifs(sequence, pos, wild)\n",
    "\n",
    "    # Load per-protein auxiliary files\n",
    "    f4_lines = open(f\"{BASE_DIR}/{uniprot_id}.pssm\", \"r\").readlines()[2:]\n",
    "    f_aacon = pd.read_csv(f\"{BASE_DIR}/{uniprot_id}.csv\", skiprows=1, names=AACON_HEADER)\n",
    "    f_disorder = pd.read_csv(f\"{BASE_DIR}/{uniprot_id}_IUPred.csv\")\n",
    "    f_depth = pd.read_csv(f\"{BASE_DIR}/{uniprot_id}_residue_depth.csv\")\n",
    "    f_plddt = pd.read_csv(f\"{BASE_DIR}/{uniprot_id}_plDDT.out\")\n",
    "    f_dssp = pd.read_csv(f\"{BASE_DIR}/{uniprot_id}.out\")\n",
    "    df_network = pd.read_csv(f\"{BASE_DIR}/{uniprot_id}_network.csv\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Feature dictionary (one row)\n",
    "    # -----------------------------\n",
    "    dict_prop = {\n",
    "        # Identifiers / metadata\n",
    "        \"UniProt ID\": uniprot_id,\n",
    "        \"Gene Name\": gene,\n",
    "        \"Mutation\": mutation,\n",
    "        \"Wild\": wild,\n",
    "        \"Mut\": mut,\n",
    "        \"Pos\": pos,\n",
    "    }\n",
    "\n",
    "    # Feature group: physicochemical properties (site + window + diffs + AA-class counts)\n",
    "    add_physchem_features(dict_prop, wild, mut, win13)\n",
    "\n",
    "    # Feature group: AAIndex mutation matrix deltas (N-term + C-term contexts)\n",
    "    add_mutation_matrix_features(dict_prop, sequence, pos, wild, mut)\n",
    "\n",
    "    # Feature group: local sequence motifs (for odds ratio)\n",
    "    for k, v in motifs.items():\n",
    "        dict_prop[k] = v\n",
    "\n",
    "    # Feature group: odds ratio features (coded + raw)\n",
    "    add_odds_ratio_features(dict_prop, motifs)\n",
    "\n",
    "    # Feature group: network centrality\n",
    "    add_network_features(dict_prop, df_network, wild, pos)\n",
    "\n",
    "    # Feature group: PSSM features\n",
    "    add_pssm_features(dict_prop, f4_lines, pos, wild, mut)\n",
    "\n",
    "    # Feature group: AACon conservation features\n",
    "    add_aacon_features(dict_prop, f_aacon, pos)\n",
    "\n",
    "    # Feature group: disorder + DSSP ASA/SS + plDDT + residue depth\n",
    "    add_disorder_depth_plddt_dssp(dict_prop, f_disorder, f_depth, f_plddt, f_dssp, pos)\n",
    "\n",
    "    # Feature group: structure-specific interaction counts\n",
    "    add_structure_interaction_counts(dict_prop, uniprot_id, pos)\n",
    "\n",
    "    # Encode secondary structure to numeric (as in original)\n",
    "    sec_map = {'B': 1, 'E': 2, 'H': 3, 'S': 4, 'T': 5, 'I': 6, '-': 0}\n",
    "    dict_prop[\"sec_strc\"] = sec_map.get(dict_prop.get(\"sec_strc\", \"-\"), 0)\n",
    "\n",
    "    all_rows.append(dict_prop)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# WRITE OUTPUT\n",
    "# -----------------------------\n",
    "all_prop = pd.DataFrame(all_rows)\n",
    "all_prop.to_csv(OUT_CSV, index=False)\n",
    "print(f\"Wrote: {OUT_CSV}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
