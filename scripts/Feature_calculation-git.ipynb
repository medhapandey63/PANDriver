{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c09c34e-3c43-44d5-a54a-16bebc0f2762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: ../output_data/complete_dataset_with_features.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Feature generation script (cleaned + labeled)\n",
    "\n",
    "Inputs expected (per UniProt ID):\n",
    "- ../data/whole_proteome_uniprot_id.xlsx                (Sequence, Entry Name, From->uniprot_ids)\n",
    "- ../data/49_properties_normalizedValues.csv            (physicochemical properties; normalized)\n",
    "- ../data/49_properties_numerical_Values.csv            (physicochemical properties; numeric)\n",
    "- ../data/463_unique_numerical_properties.csv           (additional numeric properties)\n",
    "- ../data/aaindex_square_diagonal_properties.csv        (AAindex mutation matrices; wild_mut index)\n",
    "- ../data/{uniprot_id}.pssm                             (PSSM file)\n",
    "- ../data/{uniprot_id}.csv                              (AACon conservation features)\n",
    "- ../data/{uniprot_id}_IUPred.csv                        (disorder)\n",
    "- ../data/{uniprot_id}_residue_depth.csv                 (residue depth)\n",
    "- ../data/{uniprot_id}_plDDT.out                         (plDDT / B-factor per residue)\n",
    "- ../data/{uniprot_id}.out                               (DSSP-like output with SS, ASA columns)\n",
    "- ../data/{uniprot_id}_network.csv                       (network centrality features)\n",
    "- ../data/structure_specific_interactions/{uniprot_id}_*.csv (interaction/contact files)\n",
    "\n",
    "Output:\n",
    "- ../complete_dataset_with_features.csv\n",
    "\"\"\"\n",
    "\n",
    "import random\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"openpyxl\")\n",
    "\n",
    "# -----------------------------\n",
    "# CONFIG / INPUTS\n",
    "# -----------------------------\n",
    "INPUT_FILE = \"../input_data/input.csv\"\n",
    "\n",
    "input_df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "# sanity check\n",
    "required_cols = {\"uniprot_id\", \"mutation\"}\n",
    "if not required_cols.issubset(input_df.columns):\n",
    "    raise ValueError(\"input.csv must contain columns: uniprot_id, mutation\")\n",
    "BASE_DIR = \"../data\"\n",
    "OUT_CSV = \"../output_data/complete_dataset_with_features.csv\"\n",
    "\n",
    "AA3_TO_AA1 = {\n",
    "    \"ALA\": \"A\", \"ARG\": \"R\", \"ASN\": \"N\", \"ASP\": \"D\", \"CYS\": \"C\",\n",
    "    \"GLN\": \"Q\", \"GLU\": \"E\", \"GLY\": \"G\", \"HIS\": \"H\", \"ILE\": \"I\",\n",
    "    \"LEU\": \"L\", \"LYS\": \"K\", \"MET\": \"M\", \"PHE\": \"F\", \"PRO\": \"P\",\n",
    "    \"SER\": \"S\", \"THR\": \"T\", \"TRP\": \"W\", \"TYR\": \"Y\", \"VAL\": \"V\"\n",
    "}\n",
    "\n",
    "MOTIFS = ['nM', 'Mc', 'n_M', 'M_c', 'n__M', 'M__c', 'tri']\n",
    "\n",
    "AACON_HEADER = [\n",
    "    'mut_pos', 'KABAT', 'JORES', 'SCHNEIDER', 'SHENKIN', 'GERSTEIN',\n",
    "    'TAYLOR_GAPS', 'TAYLOR_NO_GAPS', 'VELIBIL', 'KARLIN', 'ARMON',\n",
    "    'THOMPSON', 'NOT_LANCET', 'MIRNY', 'WILLIAMSON', 'LANDGRAF',\n",
    "    'SANDER', 'VALDAR', 'SMERFS'\n",
    "]\n",
    "\n",
    "CONTACT_FILES = [\n",
    "    \"_aroaro.csv\", \"_arosul.csv\", \"_cationpi.csv\", \"_disulphide.csv\",\n",
    "    \"_hbond_main_main.csv\", \"_hbond_main_side.csv\", \"_hbond_side_side.csv\",\n",
    "    \"_hydrophobic.csv\", \"_ionic.csv\"\n",
    "]\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# LOAD REFERENCE TABLES\n",
    "# -----------------------------\n",
    "uniprot_seq = pd.read_excel(f\"{BASE_DIR}/whole_proteome_uniprot_id.xlsx\", engine=\"openpyxl\")\n",
    "uniprot_seq.rename({\"From\": \"uniprot_ids\"}, axis=1, inplace=True)\n",
    "uniprot_seq[\"gene\"] = uniprot_seq[\"Entry Name\"].apply(lambda x: x.split(\"_\")[0])\n",
    "\n",
    "physchem_norm = pd.read_csv(f\"{BASE_DIR}/49_properties_normalizedValues.csv\")\n",
    "physchem_num = pd.read_csv(f\"{BASE_DIR}/49_properties_numerical_Values.csv\")\n",
    "extra_463 = pd.read_csv(f\"{BASE_DIR}/463_unique_numerical_properties.csv\")\n",
    "\n",
    "# NOTE: This creates a numeric-property table with the same columns as physchem_num\n",
    "physchem_num_all = pd.concat([physchem_norm, extra_463[physchem_num.columns]], ignore_index=True)\n",
    "\n",
    "mutation_matrices = pd.read_csv(\n",
    "    f\"{BASE_DIR}/aaindex_square_diagonal_properties.csv\",\n",
    "    keep_default_na=False\n",
    ")\n",
    "mutation_matrices.set_index(\"wild_mut\", inplace=True)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# HELPER FUNCTIONS\n",
    "# -----------------------------\n",
    "def get_sequence_and_gene(uniprot_id: str):\n",
    "    seq = next(iter(uniprot_seq.loc[uniprot_seq[\"uniprot_ids\"] == uniprot_id, \"Sequence\"]))\n",
    "    gene = next(iter(uniprot_seq.loc[uniprot_seq[\"uniprot_ids\"] == uniprot_id, \"gene\"]))\n",
    "    return seq, gene\n",
    "\n",
    "\n",
    "def window_13mer(sequence: str, pos_1based: int) -> str:\n",
    "    \"\"\"13-aa window centered on position; handles ends.\"\"\"\n",
    "    pos0 = pos_1based - 1\n",
    "    left = max(0, pos0 - 6)\n",
    "    right = min(len(sequence), pos0 + 7)\n",
    "    return sequence[left:right]\n",
    "\n",
    "\n",
    "def safe_get(series, default=0):\n",
    "    try:\n",
    "        return next(iter(series))\n",
    "    except StopIteration:\n",
    "        return default\n",
    "\n",
    "\n",
    "def compute_dipeptide_motifs(sequence: str, pos_1based: int, wild: str):\n",
    "    \"\"\"Motifs used for odds-ratio lookup.\"\"\"\n",
    "    pos0 = pos_1based - 1\n",
    "\n",
    "    # N-terminal neighbors\n",
    "    n1 = sequence[pos0 - 1] if pos0 - 1 >= 0 else '-'\n",
    "    n2 = sequence[pos0 - 2] if pos0 - 2 >= 0 else '-'\n",
    "    n4 = sequence[pos0 - 4] if pos0 - 4 >= 0 else '-'\n",
    "\n",
    "    # C-terminal neighbors\n",
    "    c1 = sequence[pos0 + 1] if pos0 + 1 < len(sequence) else '-'\n",
    "    c2 = sequence[pos0 + 2] if pos0 + 2 < len(sequence) else '-'\n",
    "    c0 = sequence[pos0 + 0] if pos0 < len(sequence) else '-'\n",
    "\n",
    "    motifs = {}\n",
    "    motifs[\"nM\"] = n1 + wild\n",
    "    motifs[\"Mc\"] = wild + c0\n",
    "    motifs[\"tri\"] = n1 + wild + c0\n",
    "    motifs[\"n_M\"] = n2 + \"*\" + wild\n",
    "    motifs[\"M_c\"] = wild + \"*\" + c1\n",
    "    motifs[\"n__M\"] = (n4 + \"**\" + wild) if n4 != '-' else ('-' + wild)\n",
    "    motifs[\"M__c\"] = wild + \"**\" + (c2 if c2 != '-' else c1)\n",
    "\n",
    "    return motifs\n",
    "\n",
    "\n",
    "def add_physchem_features(dict_prop, wild, mut, win13):\n",
    "    \"\"\"\n",
    "    Feature group: Physicochemical properties\n",
    "    - site values (wild)\n",
    "    - window mean (13-mer)\n",
    "    - diff-like features\n",
    "    \"\"\"\n",
    "    # window means across residues (ignoring non-letters)\n",
    "    denom = sum(c.isalpha() for c in win13)\n",
    "    a = sum(physchem_norm[win13[k]] for k in range(len(win13))) / denom\n",
    "    b = sum(physchem_num_all[win13[k]] for k in range(len(win13))) / denom\n",
    "\n",
    "    j = 0\n",
    "    for prop_name in physchem_norm[\"index\"]:\n",
    "        # normalized\n",
    "        wild_norm = physchem_norm.loc[physchem_norm[\"index\"] == prop_name, wild].tolist()[0]\n",
    "        mut_norm = physchem_norm.loc[physchem_norm[\"index\"] == prop_name, mut].tolist()[0]\n",
    "        dict_prop[f\"{prop_name}_normalize_site_value\"] = wild_norm\n",
    "        dict_prop[f\"{prop_name}_normalize\"] = a[j]\n",
    "        dict_prop[f\"{prop_name}_normalize_diff\"] = a[j] - mut_norm + wild_norm\n",
    "\n",
    "        # numeric (FIX: original code accidentally used \"pK'\" row for everything)\n",
    "        wild_num = physchem_num_all.loc[physchem_num_all[\"index\"] == prop_name, wild].tolist()[0]\n",
    "        mut_num = physchem_num_all.loc[physchem_num_all[\"index\"] == prop_name, mut].tolist()[0]\n",
    "        dict_prop[f\"{prop_name}_numeric_site_value\"] = wild_num\n",
    "        dict_prop[f\"{prop_name}_numeric_values\"] = b[j]\n",
    "        dict_prop[f\"{prop_name}_numeric_diff\"] = b[j] - mut_num + wild_num\n",
    "\n",
    "        j += 1\n",
    "\n",
    "    # Feature group: amino-acid class composition in 13-mer window\n",
    "    dict_prop[\"neg_charge\"] = len(re.findall(\"[DE]\", win13))\n",
    "    dict_prop[\"polar\"] = len(re.findall(\"[NQSTP]\", win13))\n",
    "    dict_prop[\"aromatic\"] = len(re.findall(\"[YFW]\", win13))\n",
    "    dict_prop[\"S_containing\"] = len(re.findall(\"[CM]\", win13))\n",
    "    dict_prop[\"aliphatic\"] = len(re.findall(\"[GALIV]\", win13))\n",
    "\n",
    "\n",
    "def add_mutation_matrix_features(dict_prop, sequence, pos, wild, mut):\n",
    "    \"\"\"\n",
    "    Feature group: AAIndex mutation matrices\n",
    "    - N-terminal context (mut_prop)\n",
    "    - C-terminal context (lowercase mut_prop)\n",
    "    \"\"\"\n",
    "    pos0 = pos - 1\n",
    "\n",
    "    # N-terminal dipeptide: (wild + previous residue)\n",
    "    prev_res = sequence[pos0 - 1] if pos0 - 1 >= 0 else \"-\"\n",
    "    n_wild = wild + prev_res\n",
    "    n_mut = mut + prev_res\n",
    "\n",
    "    # C-terminal dipeptide: (wild + next residue)\n",
    "    next_res = sequence[pos0 + 1] if pos0 + 1 < len(sequence) else \"-\"\n",
    "    c_wild = wild + next_res\n",
    "    c_mut = mut + next_res\n",
    "\n",
    "    property_n = mutation_matrices.loc[n_mut] - mutation_matrices.loc[n_wild]\n",
    "    try:\n",
    "        property_c = mutation_matrices.loc[c_mut] - mutation_matrices.loc[c_wild]\n",
    "    except KeyError:\n",
    "        property_c = mutation_matrices.loc[\"AG\"] - mutation_matrices.loc[\"AG\"]\n",
    "\n",
    "    for mut_prop in property_n.index:\n",
    "        dict_prop[mut_prop] = property_n[mut_prop]\n",
    "        dict_prop[mut_prop.lower()] = property_c[mut_prop]\n",
    "\n",
    "\n",
    "def add_odds_ratio_features(dict_prop, motifs):\n",
    "    \"\"\"\n",
    "    Feature group: Motif odds-ratio (from Excel sheets per motif)\n",
    "    Creates:\n",
    "    - {motif}_coded_odds\n",
    "    - {motif}_odds_ratio\n",
    "    \"\"\"\n",
    "    for motif in MOTIFS:\n",
    "        x = pd.read_excel(f\"{BASE_DIR}/BRCA_odds_ratio.xlsx\", sheet_name=motif)\n",
    "        entry = motifs[motif]\n",
    "        row = x[x[motif] == entry]\n",
    "\n",
    "        odd = safe_get(row[\"odd_ratio\"], default=0)\n",
    "\n",
    "        # Coded odds bins\n",
    "        conditions = [\n",
    "            (row[\"odd_ratio\"] >= 1.2) | (row[\"odd_ratio\"] == \"inf\"),\n",
    "            (row[\"odd_ratio\"] < 1.2) & (row[\"odd_ratio\"] >= 0.9),\n",
    "            (row[\"odd_ratio\"] < 0.9),\n",
    "        ]\n",
    "        code_vals = [1, 3, 2]\n",
    "        dict_prop[f\"{motif}_coded_odds\"] = safe_get(np.select(conditions, code_vals), default=0)\n",
    "        dict_prop[f\"{motif}_odds_ratio\"] = odd\n",
    "\n",
    "\n",
    "def add_network_features(dict_prop, df_network, wild, pos):\n",
    "    \"\"\"\n",
    "    Feature group: Structural network centrality\n",
    "    \"\"\"\n",
    "    xx = df_network[(df_network[\"Wild\"] == wild) & (df_network[\"pos\"] == pos)]\n",
    "    if len(xx) > 0:\n",
    "        dict_prop[\"Degree_centrality\"] = safe_get(xx[\"Degree centrality\"], 0)\n",
    "        dict_prop[\"Closeness_centrality\"] = safe_get(xx[\"Closeness centrality\"], 0)\n",
    "        dict_prop[\"betweenness_centrality\"] = safe_get(xx[\"Betweenness centrality\"], 0)\n",
    "        dict_prop[\"eigenvector_centrality\"] = safe_get(xx[\"Eigenvector centrality\"], 0)\n",
    "    else:\n",
    "        dict_prop[\"Degree_centrality\"] = 0\n",
    "        dict_prop[\"Closeness_centrality\"] = 0\n",
    "        dict_prop[\"betweenness_centrality\"] = 0\n",
    "        dict_prop[\"eigenvector_centrality\"] = 0\n",
    "\n",
    "\n",
    "def add_pssm_features(dict_prop, f4_lines, pos, wild, mut):\n",
    "    \"\"\"\n",
    "    Feature group: PSSM / conservation\n",
    "    \"\"\"\n",
    "    # PSSM line indexing: original code uses f4[pos] (1-basedish). Keep as-is to match their files.\n",
    "    cols = f4_lines[pos].strip().split()\n",
    "\n",
    "    aa_scores = cols[2:22]  # 20 AAs\n",
    "    aa_order = list(\"ARNDCQEGHILKMFPSTWYV\")\n",
    "\n",
    "    score_map = dict(zip(aa_order, aa_scores))\n",
    "    score_map = {k: int(v) for k, v in score_map.items()}\n",
    "\n",
    "    dict_prop[\"pssm_score1\"] = score_map.get(wild, 0)\n",
    "    dict_prop[\"pssm_score2\"] = sum(score_map.values()) / 20.0\n",
    "    dict_prop[\"pssm_score3\"] = score_map.get(mut, 0) - score_map.get(wild, 0)\n",
    "\n",
    "    # Conservation: original code slices at char 90; keep behavior\n",
    "    cons = f4_lines[pos].strip(\"\\n\")[90:].split()[21:22]\n",
    "    dict_prop[\"conservation\"] = float(cons[0]) if len(cons) else 0.0\n",
    "\n",
    "\n",
    "def add_aacon_features(dict_prop, f_aacon, pos):\n",
    "    \"\"\"\n",
    "    Feature group: AACon conservation features (per residue)\n",
    "    \"\"\"\n",
    "    mm = f_aacon.iloc[pos - 1]\n",
    "    for item in AACON_HEADER:\n",
    "        dict_prop[item] = mm[item]\n",
    "\n",
    "\n",
    "def add_disorder_depth_plddt_dssp(dict_prop, f_disorder, f_depth, f_plddt, f_dssp, pos):\n",
    "    \"\"\"\n",
    "    Feature group: Disorder + structure features\n",
    "    - disorder (IUPred)\n",
    "    - DSSP secondary structure + ASA\n",
    "    - plDDT\n",
    "    - residue depth\n",
    "    \"\"\"\n",
    "    dict_prop[\"disorder\"] = safe_get(\n",
    "        f_disorder.loc[f_disorder[\"Pos\"] == pos, \"IUPRED SCORE\"],\n",
    "        default=0\n",
    "    )\n",
    "\n",
    "    # DSSP and other structure files: if residue missing, use averages/random SS\n",
    "    if pos > len(f_dssp):\n",
    "        dict_prop[\"sec_strc\"] = random.choice(list(\"BEGHIST-\"))\n",
    "        dict_prop[\"ASA\"] = float(np.average(f_dssp[\"ASA\"])) if len(f_dssp) else 0\n",
    "        dict_prop[\"plDDT\"] = float(np.average(f_plddt[\"Avg. B-factor\"])) if len(f_plddt) else 0\n",
    "        dict_prop[\"f_residue_depth\"] = float(np.average(f_depth[\"depth\"])) if len(f_depth) else 0\n",
    "    else:\n",
    "        dict_prop[\"sec_strc\"] = f_dssp.iloc[pos - 1][\"SS\"]\n",
    "        dict_prop[\"ASA\"] = f_dssp.iloc[pos - 1][\"ASA\"]\n",
    "        dict_prop[\"plDDT\"] = safe_get(\n",
    "            f_plddt.loc[f_plddt[\"Residue\"] == pos, \"Avg. B-factor\"],\n",
    "            default=0\n",
    "        )\n",
    "        dict_prop[\"f_residue_depth\"] = safe_get(\n",
    "            f_depth.loc[f_depth[\"pos\"] == pos, \"depth\"],\n",
    "            default=0\n",
    "        )\n",
    "\n",
    "\n",
    "def add_structure_interaction_counts(dict_prop, uniprot_id, pos):\n",
    "    \"\"\"\n",
    "    Feature group: Structure-specific interaction/contact counts\n",
    "    Each file contributes one count feature keyed by interaction type.\n",
    "    \"\"\"\n",
    "    for suffix in CONTACT_FILES:\n",
    "        f_type = f\"{uniprot_id}{suffix}\"\n",
    "        df_bonds = pd.read_csv(f\"{BASE_DIR}/structure_specific_interactions/{f_type}\")\n",
    "\n",
    "        # Normalize residue labels and positions\n",
    "        df_bonds[\"Res1\"] = df_bonds[\"RES1 \"].apply(lambda x: AA3_TO_AA1[x.strip()])\n",
    "        df_bonds[\"Res2\"] = df_bonds[\" RES2 \"].apply(lambda x: AA3_TO_AA1[x.strip()])\n",
    "        df_bonds.rename({\" idRES1 \": \"pos1\", \" idRES2 \": \"pos2\"}, axis=1, inplace=True)\n",
    "\n",
    "        interaction_name = f_type.split(\"_\")[-1].split(\".\")[0]\n",
    "        dict_prop[interaction_name] = int((df_bonds[\"pos1\"] == pos).sum())\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# MAIN: BUILD FEATURE TABLE\n",
    "# -----------------------------\n",
    "all_rows = []\n",
    "\n",
    "for _, row in input_df.iterrows():\n",
    "    uniprot_id = row[\"uniprot_id\"]\n",
    "    mutation = row[\"mutation\"]\n",
    "\n",
    "    wild = mutation[0]\n",
    "    mut = mutation[-1]\n",
    "    pos = int(mutation[1:-1])  # 1-based residue index\n",
    "\n",
    "    sequence, gene = get_sequence_and_gene(uniprot_id)\n",
    "\n",
    "    # Basic validation: position exists and wild matches sequence at that position\n",
    "    if not (1 <= pos <= len(sequence)) or sequence[pos - 1] != wild:\n",
    "        # Skip invalid entries (instead of silently doing nothing)\n",
    "        continue\n",
    "\n",
    "    win13 = window_13mer(sequence, pos)\n",
    "    motifs = compute_dipeptide_motifs(sequence, pos, wild)\n",
    "\n",
    "    # Load per-protein auxiliary files\n",
    "    f4_lines = open(f\"{BASE_DIR}/{uniprot_id}.pssm\", \"r\").readlines()[2:]\n",
    "    f_aacon = pd.read_csv(f\"{BASE_DIR}/{uniprot_id}.csv\", skiprows=1, names=AACON_HEADER)\n",
    "    f_disorder = pd.read_csv(f\"{BASE_DIR}/{uniprot_id}_IUPred.csv\")\n",
    "    f_depth = pd.read_csv(f\"{BASE_DIR}/{uniprot_id}_residue_depth.csv\")\n",
    "    f_plddt = pd.read_csv(f\"{BASE_DIR}/{uniprot_id}_plDDT.out\")\n",
    "    f_dssp = pd.read_csv(f\"{BASE_DIR}/{uniprot_id}.out\")\n",
    "    df_network = pd.read_csv(f\"{BASE_DIR}/{uniprot_id}_network.csv\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Feature dictionary (one row)\n",
    "    # -----------------------------\n",
    "    dict_prop = {\n",
    "        # Identifiers / metadata\n",
    "        \"UniProt ID\": uniprot_id,\n",
    "        \"Gene Name\": gene,\n",
    "        \"Mutation\": mutation,\n",
    "        \"Wild\": wild,\n",
    "        \"Mut\": mut,\n",
    "        \"Pos\": pos,\n",
    "    }\n",
    "\n",
    "    # Feature group: physicochemical properties (site + window + diffs + AA-class counts)\n",
    "    add_physchem_features(dict_prop, wild, mut, win13)\n",
    "\n",
    "    # Feature group: AAIndex mutation matrix deltas (N-term + C-term contexts)\n",
    "    add_mutation_matrix_features(dict_prop, sequence, pos, wild, mut)\n",
    "\n",
    "    # Feature group: local sequence motifs (for odds ratio)\n",
    "    for k, v in motifs.items():\n",
    "        dict_prop[k] = v\n",
    "\n",
    "    # Feature group: odds ratio features (coded + raw)\n",
    "    add_odds_ratio_features(dict_prop, motifs)\n",
    "\n",
    "    # Feature group: network centrality\n",
    "    add_network_features(dict_prop, df_network, wild, pos)\n",
    "\n",
    "    # Feature group: PSSM features\n",
    "    add_pssm_features(dict_prop, f4_lines, pos, wild, mut)\n",
    "\n",
    "    # Feature group: AACon conservation features\n",
    "    add_aacon_features(dict_prop, f_aacon, pos)\n",
    "\n",
    "    # Feature group: disorder + DSSP ASA/SS + plDDT + residue depth\n",
    "    add_disorder_depth_plddt_dssp(dict_prop, f_disorder, f_depth, f_plddt, f_dssp, pos)\n",
    "\n",
    "    # Feature group: structure-specific interaction counts\n",
    "    add_structure_interaction_counts(dict_prop, uniprot_id, pos)\n",
    "\n",
    "    # Encode secondary structure to numeric (as in original)\n",
    "    sec_map = {'B': 1, 'E': 2, 'H': 3, 'S': 4, 'T': 5, 'I': 6, '-': 0}\n",
    "    dict_prop[\"sec_strc\"] = sec_map.get(dict_prop.get(\"sec_strc\", \"-\"), 0)\n",
    "\n",
    "    all_rows.append(dict_prop)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# WRITE OUTPUT\n",
    "# -----------------------------\n",
    "all_prop = pd.DataFrame(all_rows)\n",
    "all_prop.to_csv(OUT_CSV, index=False)\n",
    "print(f\"Wrote: {OUT_CSV}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
